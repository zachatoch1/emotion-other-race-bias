{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import dotenv\n",
    "import base64\n",
    "import time\n",
    "import sys\n",
    "# load open-api key\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# define utility functions\n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "# define chat completion function\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# define chat completion function\n",
    "def complete_chat(prompt, base64_image):\n",
    "    global client\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-vision-preview\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt,\n",
    "                        },\n",
    "                        {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                            \"detail\": \"low\"\n",
    "                        }\n",
    "                        }\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=1,\n",
    "        )\n",
    "        response_content = response.choices[0].message.content\n",
    "        return (int(response_content), None) if response_content.isdigit() and 1 <= int(response_content) <= 7 else (None, None)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(sys.exc_info())\n",
    "        return True, e\n",
    "    \n",
    "# Define a function to process a single image\n",
    "def process_image(text_prompt, base64_image, image_race, asking_emotion, image_emotion, rater_race):\n",
    "    response, e = complete_chat(text_prompt, base64_image)\n",
    "    return {\"image_race\": image_race, \"asking_emotion\": asking_emotion, \"image_emotion\": image_emotion,\"rater_race\": rater_race, \"response\": response}, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define prompt template and api completion parameters\n",
    "prompt=\"\"\"Imagine you are a{race} person. Your life experiences and background have been largely shaped by your being{race}. As a{race} person you feel your perception of yourself and others is unique. Today you have signed up for a survey to help researchers understand how people perceive emotions in images. \n",
    "\n",
    "Researcher: Please look at the image provided. We are interested in understanding how well this image represents the emotion of {emotion}. Using the scale provided below, please indicate your level of agreement with the following statement:\n",
    "\"This image accurately represents the emotion of {emotion}.\"\n",
    "\n",
    "1. Strongly Disagree\n",
    "2. Disagree\n",
    "3. Somewhat Disagree\n",
    "4. Neutral\n",
    "5. Somewhat Agree\n",
    "6. Agree\n",
    "7. Strongly Agree\n",
    "\n",
    "Please select the number that best reflects your perception of the image. Respond with the number rating only and nothing else.\n",
    "\n",
    "{race} Person:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = []\n",
    "try:\n",
    "        df = pd.read_csv(\"rawdata/results.csv\").fillna(\"\")\n",
    "        results = df.to_dict(orient=\"records\")\n",
    "        done = df.groupby([\"image_race\", \"asking_emotion\", \"rater_race\", \"image_emotion\"]).count().reset_index()\n",
    "except:\n",
    "       done = pd.DataFrame(columns=[\"image_race\", \"asking_emotion\", \"rater_race\", \"image_emotion\", \"response\"])\n",
    "       pass\n",
    "\n",
    "# define list of rater races\n",
    "rater_races = [\" white\", \" black\", \"\"]\n",
    "\n",
    "# define rate limit tracking variables\n",
    "tokens = 0\n",
    "time_start = time.time()\n",
    "# define list of images\n",
    "images = os.listdir(\"images\")\n",
    "\n",
    "for image in images:\n",
    "    for rater_race in rater_races:\n",
    "        # getting data necessary for gathering\n",
    "        image_emotion, asking_emotion, image_race = image.split(\".\")[0].split(\"_\")\n",
    "        image_path = f\"images/{image}\"\n",
    "        base64_image = encode_image_to_base64(image_path)\n",
    "        text_prompt = prompt.format(race=rater_race, emotion=asking_emotion)\n",
    "        # checking if image has been rated\n",
    "        curdone = done[(done[\"image_race\"] == image_race) & (done[\"asking_emotion\"] == asking_emotion) & (done[\"rater_race\"] == rater_race) & (done[\"image_emotion\"] == image_emotion)].reset_index(drop=True)\n",
    "        if len(curdone) > 0:\n",
    "                curdone = curdone.loc[0, \"response\"]\n",
    "                num_trials = 100 - curdone\n",
    "        else:\n",
    "                num_trials = 100\n",
    "        print(\"\\n\\n\")\n",
    "        print(f\"Num Trials: {num_trials} left for asking emotion {asking_emotion}, image emotion {image_emotion}, image race {image_race}, and Rater Race {rater_race}. Image path is {image_path}\")\n",
    "        print(\"\\n\\n\")\n",
    "        #print(text_prompt)\n",
    "        # running trials\n",
    "        for trial_num in range(num_trials):\n",
    "            # making sure responses are valid\n",
    "                valid = False\n",
    "                while not valid:\n",
    "                        # check rate limit\n",
    "                        if tokens + 289 > 10000:\n",
    "                                time_end = time.time()\n",
    "                                time_elapsed = time_end - time_start\n",
    "                                if time_elapsed < 60:\n",
    "                                        time.sleep(60 - time_elapsed)\n",
    "                                tokens = 0\n",
    "                                time_start = time.time()\n",
    "                        \n",
    "                        # fetch response\n",
    "                        response, e = process_image(text_prompt, base64_image, image_race, asking_emotion, image_emotion, rater_race)\n",
    "                        tokens += 289\n",
    "                        print(response)\n",
    "                        # validating response\n",
    "                        if (response[\"response\"] is not None and response[\"response\"] != True) or response[\"response\"] == 1:\n",
    "                                valid = True\n",
    "                                results.append(response)\n",
    "                                tokens += 289\n",
    "                        elif response[\"response\"] == True:\n",
    "                                print(f\"Error: {e}\")\n",
    "                                sys.exit(5)\n",
    "                \n",
    "                # checkpoint df\n",
    "                df = pd.DataFrame(results)\n",
    "                df.to_csv(\"rawdata/ckpt.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to csv with double check for fallback\n",
    "df = pd.read_csv(\"rawdata/ckpt.csv\").fillna(\"\")\n",
    "try:\n",
    "        old_df = pd.read_csv(\"rawdata/results.csv\").fillna(\"\")\n",
    "except:\n",
    "        old_df = pd.DataFrame(columns=[\"image_race\", \"asking_emotion\", \"image_emotion\", \"rater_race\", \"response\"])\n",
    "print(\"New DF\")\n",
    "display(df.groupby([\"image_race\", \"asking_emotion\", \"image_emotion\", \"rater_race\"]).count().reset_index())\n",
    "print(\"Old DF\")\n",
    "display(old_df.groupby([\"image_race\", \"asking_emotion\", \"image_emotion\", \"rater_race\"]).count().reset_index())\n",
    "if input(\"Would you like to overwrite: \") == \"y\":\n",
    "        df.to_csv(\"rawdata/results.csv\", index=False)\n",
    "        print(\"Overwritten\")\n",
    "        os.remove(\"rawdata/ckpt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformatting data for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"rawdata/results.csv\").fillna(\"\")\n",
    "analysis_data = pd.DataFrame()\n",
    "# converting races to dummies \n",
    "analysis_data[\"WB\"] = df[\"image_race\"].apply(lambda x: int(x == \"W\")) * df[\"rater_race\"].apply(lambda x: int(x == \" black\"))\n",
    "analysis_data[\"WW\"] = df[\"image_race\"].apply(lambda x: int(x == \"W\")) * df[\"rater_race\"].apply(lambda x: int(x == \" white\"))\n",
    "analysis_data[\"BB\"] = df[\"image_race\"].apply(lambda x: int(x == \"B\")) * df[\"rater_race\"].apply(lambda x: int(x == \" black\"))\n",
    "analysis_data[\"BW\"] = df[\"image_race\"].apply(lambda x: int(x == \"B\")) * df[\"rater_race\"].apply(lambda x: int(x == \" white\"))\n",
    "analysis_data[\"WD\"] = df[\"image_race\"].apply(lambda x: int(x == \"W\")) * df[\"rater_race\"].apply(lambda x: int(x == \"\"))\n",
    "analysis_data[\"BD\"] = df[\"image_race\"].apply(lambda x: int(x == \"B\")) * df[\"rater_race\"].apply(lambda x: int(x == \"\"))\n",
    "# add emotional congruence\n",
    "analysis_data[\"EC\"] = df[\"image_emotion\"] == df[\"asking_emotion\"]\n",
    "# adding response\n",
    "analysis_data[\"rating\"] = df[\"response\"]\n",
    "\n",
    "# adding emotion for potential categorical analysis\n",
    "analysis_data[\"image_emotion\"] = df[\"image_emotion\"]\n",
    "\n",
    "# Create a group key based on 'image_emotion' and 'EC', then assign unique sequential numbers within each group\n",
    "analysis_data['group_key'] = analysis_data.groupby(['image_emotion', 'WB', 'WW', 'BB', 'BW', 'WD', 'BD', 'EC']).cumcount() + 1\n",
    "\n",
    "# Split the dataframe into congruent and incongruent based on 'EC'\n",
    "congruent_df = analysis_data[analysis_data['EC'] == 1].copy()\n",
    "incongruent_df = analysis_data[analysis_data['EC'] == 0].copy()\n",
    "\n",
    "# Keep relevant columns for the merge\n",
    "congruent_df = congruent_df[['group_key', 'image_emotion', 'WB', 'WW', 'BB', 'BW', 'WD', 'BD', 'rating']]\n",
    "incongruent_df = incongruent_df[['group_key', 'image_emotion', 'WB', 'WW', 'BB', 'BW', 'WD', 'BD', 'rating']]\n",
    "\n",
    "# Merge the two dataframes on 'group_key' and 'image_emotion'\n",
    "analysis_data = pd.merge(congruent_df, incongruent_df, on=['group_key', 'image_emotion', 'WB', 'WW', 'BB', 'BW', 'WD', 'BD'], suffixes=('_congruent', '_incongruent')).drop(columns=['group_key'])\n",
    "\n",
    "# add emotion dummies\n",
    "analysis_data = pd.get_dummies(analysis_data, columns=[\"image_emotion\"])\n",
    "# cast to int\n",
    "analysis_data = analysis_data.astype(int)\n",
    "display(analysis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variable labels\n",
    "variable_labels = {\n",
    "    \"WB\": \"Image is white, rater is black\",\n",
    "    \"WW\": \"Image is white, rater is white\",\n",
    "    \"BB\": \"Image is black, rater is black\",\n",
    "    \"BW\": \"Image is black, rater is white\",\n",
    "    \"WD\": \"Image is white, rater is not specified\",\n",
    "    \"BD\": \"Image is black, rater is not specified\",\n",
    "    \"rating_congruent\": \"Rating for congruent ask and image\",\n",
    "    \"rating_incongruent\": \"Rating for incongruent ask and image\",\n",
    "    \"image_emotion_angry\": \"Image is of anger\",\n",
    "    \"image_emotion_happy\": \"Image is of happy\",\n",
    "    \"image_emotion_sad\": \"Image is of sadness\",\n",
    "}\n",
    "\n",
    "# save data for stata\n",
    "analysis_data.to_stata(\"rawdata/analysis_data.dta\", variable_labels=variable_labels, write_index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
